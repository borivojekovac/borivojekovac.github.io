# Chanting to Ghosts
## The stigma of today's agentic coding assistants - they look like sci-fi materialised, but in reality they's just infocracy's snake oil. Is that really true? Can agents write anything beyond unit tests?

The dark room smelled of espresso and ambition. A brilliant idea burned somewhere behind the optic nerve, waiting to flare to life on a 26-inch monitor. The agents waited patiently for her command - ready to throw themselves at the work. Only the dust packed into the screen’s corners - still dodging microfiber assaults - hinted at imperfection.

She typed... No. Even though it's one in the morning, there's nobody to wake up. Full throttle. She tapped the pale outline of the microphone icon at the bottom of the input field on her dark theme, and recited the opening instructions. A couple of follow-ups came back. Some of them unexpectedly original. “Good boy,” she thought, with a faint smile. Then the alphanumerics started to pour into the Cascade. Surfing the inference waves had begun. A filthy expensive GPU on the other side of the planet started gulping watts. An air current shoved the heat off aluminum and into some distant September afternoon. A swarm of agents pumped modern hieroglyphs at inhuman speeds into an intricate file structure.

Two sips of arabica later, a report arrived. Task completed. The reflections of a newborn synthetic entity shimmered in the concave lenses of her Etnia Barcelonas. A few incantations and an unclear number of minutes later, the idea was there - materialized on the screen in front of her. Born in the occult tongue of a flesh-and-blood mother and a synthetic father, an electronic storm in the labyrinth of Taiwanese silicon, ready to conquer the world.

The sound of the automated gate snapped her out of the trance. It's Tuesday, five in the morning; the neighbor's leaving for work. Three hours of sleep. Shit. The shower can wait. Under a thick duvet - and despite meditation worthy of the Buddha himself - the smile refused to leave.

Monday. Yet another influencer, buzzing from their channel, explained to the world why, in only six days, more than half a million people had installed a new revolutionary piece of software. Her software. Half a million of her children rushing through processor cores across the planet. The stage is set. Here we go.

A good movie.

In reality, though, it would take more than a day. And then, after say three days, the file structure would get so "intricate" that even the metaphor of modern hieroglyphs would feel too kind for the miserable state of that vibe-coded mess. A pile of gorgeous, unusable trash - and behind it, wasted electricity that could power a small South African village for a month. Without half a million users, of course.

Or maybe not?

An honest answer demands we scratch beneath the skin of our virtual puppets. If we resist the feeling that we're exchanging ideas with intelligent beings, and insist on remembering that the large language models at the heart of autonomous agents are exactly what the name implies - very large, but still just simple statistical models of human language - it gets easier to see them for what they are. A tool. And using a tool requires mastery. In Michelangelo's hands, hammer and chisel can make David. In unskilled hands, they can only make blisters.

Regardless of years of experience in the industry, the first thing one has to admit is that we're all dilettantes when it comes to these tools. Because they are unusual and unlike anything we've met before. Probabilistic. With the knowledge of humankind compressed into the weights of virtual synapses. Recursive functions with trillions of internal parameters, hundreds of thousands of numbers at the input and one at the output. Weird.

Every word we feed an LLM shapes the set of possible outcomes. Well-[chosen words](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-the-openai-api "OpenAI's Best practices for prompt engineering") sharpen the focus. But equally - noise in, noise out. And we have a lot of words available - imagine War and Peace, the Lord of the Rings trilogy, and Dune [all at once](https://developers.googleblog.com/en/new-features-for-the-gemini-api-and-google-ai-studio/ "Google Gemini 1.5 Pro's 2 million tokens context window"). How many words do you use? Do you even know [which ones](https://code.visualstudio.com/docs/copilot/chat/copilot-chat-context "GitHub Copilot's documentation on chat context building")? Alongside the text you type by hand, there are the model vendor's system instructions, the agent developer's instructions, information about your source code, snippets of prior conversation, [rules](https://docs.windsurf.com/windsurf/cascade/memories "Windsurf's rules"), [workflows](https://docs.windsurf.com/windsurf/cascade/workflows "Windsuft's workflows")… You actually do have power over a significant part of this. But you don't use it. You hand it over to your “colleague” agent. You shoot with your eyes closed and then wonder why you hit the referee instead of the target.

How much do you trust that the result matches your intent? If we go back to our Michelangelo, I can picture him taking two steps back after every hammer strike, looking at the result, before he swings again. Do you check? How do you check? Which [model](https://cursor.com/docs/models "Cursor models") do you use for which step? Why?

With a deeper understanding of the tool, with more practice, the ideal of an electronic Michelangelo becomes reachable. But let's not fool ourselves that a few hours are enough for any kind of mastery. Just as a Scrum Master [doesn't become a master after a two-day course](https://www.linkedin.com/posts/kentbeck_23-leaving-facebook-kent-beck-being-activity-6442911976111906816-rPJS/ "Ken Beck's interview on Being Human"), you don't become a master of an agentic development environment after three prompts. Remember the [10,000-hour rule](https://web.mit.edu/6.969/www/readings/expertise.pdf "K. Anders Ericsson and Neil Chamess' Expert Performance")?

I'm here to tell you: nobody is a master of these tools yet. But as someone who maybe took 10% of the journey, I’d file the opening episode in the Blue Ant more than the Sprawl lore. The choice depending on the cast is rather than the ambiance. The [future is already here - it’s just not evenly distributed](https://www.goodreads.com/quotes/681-the-future-is-already-here-it-s-just-not-evenly "Quote on Goodreads"). What will you do about it?