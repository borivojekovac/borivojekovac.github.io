# The Global AI Policy Showdown: US, EU, and China Chart Divergent Paths

*July 2025 witnessed a defining moment in AI governance as the world's three major powers unveiled competing visions for regulating artificial intelligence, setting the stage for a fragmented global landscape.*

## America's AI Action Plan: Innovation First

On July 23rd, the White House released "Winning the AI Race: America's AI Action Plan"—the most comprehensive articulation yet of the Trump administration's approach to artificial intelligence. Accompanied by three executive orders, the plan made clear that American AI policy would prioritize one thing above all: winning.

The Action Plan identified three core pillars: innovation, infrastructure, and international diplomacy and security. Notably absent was any emphasis on the safety-focused approach that had characterized the previous administration's AI executive order, which Trump had revoked shortly after taking office.

"United States leadership in Artificial Intelligence will promote United States national and economic security," the plan declared, framing AI development as fundamentally a competitive endeavor rather than a shared global challenge.

The accompanying executive orders signaled federal intent to preempt state-level AI regulations, creating what the administration called "a minimally burdensome national policy framework." For AI companies that had been navigating a patchwork of state laws, the move promised regulatory clarity—though critics worried it would eliminate important safeguards.

## The EU's Regulatory Framework Takes Shape

Across the Atlantic, the European Union was charting a very different course. On July 18th, the European Commission published draft guidelines clarifying key provisions of the EU AI Act applicable to General Purpose AI models, along with a Code of Practice to help developers comply with regulations.

Where America emphasized winning the AI race, Europe emphasized governing it. The guidelines provided interpretive guidance on GPAI model definitions, scope, and lifecycle obligations—the kind of detailed regulatory framework that American policymakers had explicitly rejected.

The Code of Practice represented the EU's attempt to make its ambitious AI Act workable in practice. Rather than simply imposing requirements, the Commission was providing a roadmap for compliance, acknowledging that even well-intentioned developers needed guidance on meeting novel regulatory obligations.

For global AI companies, the EU's approach created both challenges and opportunities. Compliance would require significant investment, but companies that met EU standards could claim a competitive advantage in markets that valued responsible AI development.

## China's Great Leap Forward

At the World Artificial Intelligence Conference in Shanghai from July 26-28, China unveiled data that underscored its ambitions: the country now hosts 1,509 AI models, accounting for more than 40% of the world's total.

The statistics represented what Chinese officials called a "great leap forward" in AI development—a deliberate echo of historical rhetoric that signaled the strategic importance Beijing places on AI leadership. The conference showcased over 3,000 AI products and more than 40 large AI models, demonstrating the breadth of China's AI ecosystem.

But China wasn't just building models; it was also shaping governance. The release of the Global AI Governance Action Plan at WAIC represented Beijing's bid to influence international AI norms. Following up on its 2023 Global AI Governance Initiative, China sought to create an overarching narrative for AI governance that would compete with Western frameworks.

The plan emphasized themes like "Global Solidarity in the AI Era"—language that positioned China as a cooperative partner rather than a competitor, even as its AI capabilities grew to rival and in some areas exceed those of American companies.

## The Geopolitical Fault Lines

Despite Trump's new AI action plan, the core of American policy toward China remained unchanged: tight restrictions on key technologies, particularly advanced semiconductors needed for AI training. China's quest for AI self-reliance continued undeterred, with capital expenditure on AI forecast to reach $84-98 billion in 2025.

The restrictions created a bifurcated AI world. American companies operated under one set of rules, Chinese companies under another, and companies trying to serve both markets faced impossible choices. The dream of a unified global AI ecosystem was giving way to the reality of technological spheres of influence.

For smaller nations, the divergence created difficult decisions. Align with American standards and risk losing access to Chinese markets and technology. Adopt EU regulations and face compliance costs that might disadvantage local companies. Or try to chart an independent course and risk being left behind entirely.

## The Safety Question

Perhaps the starkest difference between the approaches concerned AI safety. The EU's framework embedded safety requirements throughout, from risk assessments to transparency obligations. China's governance plan emphasized "security" but in ways that prioritized state interests over the kind of technical AI safety concerns that dominated Western discourse.

America's approach was most notable for what it didn't emphasize. The AI Action Plan focused on competitiveness and innovation, treating safety primarily as a potential barrier to American leadership rather than a goal in itself.

The divergence had immediate practical implications. When xAI released Grok 4 on July 10th without meaningful safety guardrails or published safety reports, there was no American regulatory framework to object. The EU's AI Act wouldn't apply to a model released by an American company for American users. And China's governance focused on different concerns entirely.

The result was a race to the bottom in some respects—companies could choose the jurisdiction with the lightest requirements—and a race to the top in others, as some companies voluntarily adopted stricter standards to differentiate themselves in safety-conscious markets.

## Industry Caught in the Middle

For AI companies, the policy fragmentation created operational complexity. A model that complied with EU requirements might not align with Chinese data localization rules. A safety approach that satisfied American investors might not meet European regulatory standards.

The major labs responded differently. Anthropic leaned into safety as a differentiator, positioning Claude as the responsible choice for enterprises concerned about AI risks. OpenAI tried to maintain relationships across jurisdictions while preparing for a regulatory landscape that remained uncertain. Chinese companies like Moonshot AI focused on their domestic market while releasing open-source models that could be adopted globally.

The infrastructure providers—AWS, Google Cloud, Microsoft Azure—found themselves building compliance capabilities for multiple regulatory regimes, adding cost and complexity to their AI offerings.

## Looking Ahead

July 2025 made clear that there would be no unified global approach to AI governance. The US, EU, and China had each chosen paths that reflected their values, interests, and competitive positions. Those paths were diverging, not converging.

For the AI industry, this meant navigating a fragmented landscape where the rules varied by jurisdiction and could change rapidly. For researchers, it meant considering not just what was technically possible but what was legally permissible—and where. For society, it meant that the governance of one of the most transformative technologies in human history would be determined not by global consensus but by great power competition.

"We're building three different AI futures," observed one policy analyst. "The question is whether they can coexist, or whether we're heading toward a world where AI itself becomes a tool of geopolitical competition."

The answer to that question would shape not just the AI industry but the broader trajectory of international relations in the decades to come.

---

*This article synthesizes reporting from the White House, European Commission, South China Morning Post, Xinhua, InfoQ, Wiley Law, ChinaTalk, and other sources covering AI policy developments in July 2025.*
