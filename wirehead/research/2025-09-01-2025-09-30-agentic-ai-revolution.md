# The Agentic Revolution: AI Learns to Act, Not Just Answer

*September 2025*

September 2025 marked a decisive shift in artificial intelligence: the transition from AI that answers questions to AI that takes action. Across the industry, from startups to tech giants, the focus moved from chatbots to agents—autonomous systems capable of executing multi-step tasks, manipulating files, browsing the web, and even controlling physical robots.

## Claude Sonnet 4.5: The New Coding Champion

Anthropic set the tone on September 29 with the release of Claude Sonnet 4.5, which the company boldly proclaimed "the best coding model in the world." The claim wasn't mere marketing bluster. On OSWorld, a benchmark that tests AI models on real-world computer tasks, Sonnet 4.5 achieved 61.4%—up from 42.2% just four months earlier with Sonnet 4.

"We're seeing state-of-the-art coding performance," Anthropic announced. "Experts in finance, law, medicine, and STEM found Sonnet 4.5 shows significant improvements in complex reasoning and task completion."

The model's capabilities extend beyond code. Earlier in September, Anthropic announced that Claude can now create and edit actual files—Excel spreadsheets, PowerPoint presentations, PDFs—working from uploaded data or building from scratch. "Claude creates actual files from your instructions," the company explained, "whether working from uploaded data, researching information, or building from scratch."

The implications for knowledge work are profound. Tasks that once required human hands on keyboard—formatting documents, building presentations, analyzing spreadsheets—can now be delegated to an AI agent.

## Microsoft's 'Vibe Working' Vision

Microsoft matched Anthropic's ambitions with its own agentic announcement. On September 29, the company introduced "Agent Mode" and "Office Agent" in Microsoft 365 Copilot, branding the concept as "vibe working."

The new capabilities allow Copilot to perform multi-step, iterative tasks within Office applications. In Excel, Agent Mode can analyze data, create formulas, and generate charts without step-by-step human guidance. In Word, it can draft, revise, and format documents autonomously. In PowerPoint, it can build entire presentations from a brief prompt.

"Available on desktop and mobile devices, Agent Mode brings multi-step, iterative AI assistance that can create and edit files in Excel, Word, and PowerPoint autonomously," Microsoft announced.

The company also revealed that it now favors Anthropic's Claude over OpenAI's models for certain tasks in Visual Studio Code. Paid GitHub Copilot users will see automatic model selection that chooses between Claude Sonnet 4, GPT-5, and other models based on the task at hand—a notable shift given Microsoft's massive investment in OpenAI.

## Notion 3.0: Agents for Everyone

Notion joined the agentic wave on September 18 with the release of Notion 3.0, its most significant update ever. At the center: AI Agents that can operate autonomously within Notion workspaces.

"With Notion 1.0 and 2.0, we gave you the tools to do your work in one place," co-founder Akshay Kothari wrote. "With 3.0, you get Agents that do the work for you, so you can reclaim time and focus on building your life's work."

Notion's agents can analyze large datasets across multiple pages and databases, generate meeting notes, and execute multi-step database operations—updating or creating hundreds of pages in a single operation. According to the company, agents can sustain tasks for over 20 minutes, far longer than typical AI interactions.

The release positions Notion as more than a note-taking app; it's now a platform for delegating work to AI.

## Google's Physical Agents

Perhaps the most ambitious agentic announcement came from Google DeepMind on September 25: Gemini Robotics 1.5, a system that brings AI agents into the physical world.

The system combines two specialized models. Gemini Robotics-ER 1.5 serves as a "high-level brain," orchestrating activities, planning tasks, and making logical decisions. It can search the web for information—for example, looking up local recycling guidelines—and then instruct Gemini Robotics 1.5, which directly controls robot actions.

"For example, if a robot was asked, 'Based on my location, can you sort these objects into the correct compost, recycling and trash bins?' it would need to search for relevant local recycling guidelines on the internet, look at the objects in front of it and figure out how to sort them based on those rules—and then do all the steps needed to completely put them away," Google explained.

The robots can even explain their reasoning in natural language, making their decision-making transparent. It's a significant step toward robots that can handle the messy, context-dependent tasks of the real world.

## OpenAI's Commerce Agents

OpenAI took a different approach to agentic AI: commerce. On September 29, the company launched "Instant Checkout" in ChatGPT, powered by what it calls the "Agentic Commerce Protocol."

Users can now purchase items directly through ChatGPT from merchants like Etsy and Shopify without leaving the app. The AI handles the entire transaction—finding products, comparing options, and completing the purchase.

"More than 700 million people turn to ChatGPT each week for help with everyday tasks, including finding products they love," OpenAI noted. The announcement sent Etsy's stock up 16%.

The move signals OpenAI's ambitions beyond subscriptions. Reports emerged in September that the company is searching for a "head of ads"—suggesting that agentic commerce may be just the beginning of ChatGPT's commercial evolution.

## The Agentic Browser

Google also brought agentic capabilities to its most ubiquitous product: Chrome. The September 18 announcement introduced Gemini integration with agentic features, allowing the AI to perform actions on behalf of users.

"We're taking you behind the browser to show you how AI is being built into Chrome to help you get things done while staying safe online," Google said, unveiling 10 new AI features including intelligent tab management, automated form filling, and proactive assistance.

Microsoft Teams, meanwhile, filled with AI agents capable of automating workflows and completing tasks within the collaboration platform.

## The Implications

The agentic shift raises profound questions about the future of work. If AI can draft documents, analyze data, build presentations, shop for products, and even control robots—what remains for humans to do?

Microsoft CEO Satya Nadella seemed to grapple with this question publicly. In a September town hall, he expressed being "haunted" by the prospect of Microsoft not surviving the AI era—a remarkable admission from the leader of one of the world's most valuable companies.

The answer, for now, seems to be that humans remain in the loop—setting goals, reviewing outputs, making final decisions. But the loop is getting smaller. As agents become more capable, the human role shifts from doing to directing.

September 2025 didn't mark the end of that transition, but it may have marked the point of no return. The agentic era has begun.

---

*Sources: Anthropic, Microsoft, Notion, Google DeepMind, OpenAI, The Verge, AWS, Google Cloud*
